# PCA_feature_extraction_and_dimensionality-reduction_ML
Applications of Artificial Intelligence, Machine Learning models and statistical effect of the PCA algorithm.

Feature Extraction and Dimensionality Reduction with Principal Component Analysis (PCA)  and Comparison Accurancy 6 Machine Learning Models : before-after PCA
  
Step 1:   Collect Data: UCI Parkinson's Disease Classification Data Set

Step 2:   Eigendecomposition - Eigenvalues, Eigenvectors and Eigenspace

Step 3:   Primary Component Selection

Step 4:   Projection New Feature Space

Step 5:   Principal Component Analysis (PCA)

Step 6:   Comparison Accurancy 6 Machine Learning Models : before-after PCA

1. Model : Logistic Regression

2. Model : Support Vector Machines (SVM)

3. Model : Decision Tree Classifier

4. Model : KNN(k-nearest neighbors algorithm)

5. Model : Random Forest Classifier

6. Model: Gaussian Naive Bayes


Collect Data: UCI Parkinson's Disease Classification Data Set
https://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification



**Note:** *I chose the (n_components)top 6 components with the highest variance. anyone can give a different number. It is an optional choice. Decide to process only 6 of the 754 features with the highest variance. It reduces the size very much and enables fast processing and only the most effective features will be processed.
PCA enabled only 6 variables to be processed instead of 754 variables.*
